{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T11:33:37.792473Z",
     "start_time": "2024-02-08T11:33:37.116749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Импортируем основные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Важная настройка для корректной настройки pipeline!\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# for model learning\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    ")\n",
    "\n",
    "# models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingClassifier, BaggingClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# tunning hyperparamters model\n",
    "import optuna\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Подгружаем отображение графиков\n",
    "from graphs import display_cat_features, display_corr, get_report, display_nan, display_target, display_zero\n",
    "\n",
    "# Подгружаем препроцессинг для наших данных\n",
    "from preprocessing import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T11:35:21.222030Z",
     "start_time": "2024-02-08T11:35:20.758533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Включаем настройку для отображения всех столбцов датафреймов\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем тренировочные данные\n",
    "graph_data = pd.read_csv(\"train.csv\")\n",
    "graph_data_cat = graph_data.select_dtypes(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Распределение категориальные признаки\n",
    "display_cat_features(graph_data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4416e67febe746ce85f2f35eb5137b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |               | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# Получаем отчет по нашим данным\n",
    "get_report(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим матрицу корреляций\n",
    "display_corr(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nan(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#·Отображаем·сколько·нулей·там,·где·есть·нули\n",
    "display_zero(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображаем распределение целевого признака\n",
    "display_target(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем датасет\n",
    "df_train, df_test = pd.read_csv(\"train.csv\"), pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# Cохраняем id, оно пригодится нам позднее\n",
    "id = df_test[\"Id\"]\n",
    "\n",
    "# Отделяем таргет от признаков\n",
    "df_train, y = df_train.drop(\"SalePrice\", axis=1), df_train[\"SalePrice\"] \n",
    "\n",
    "# Проверяем на дубликаты\n",
    "df_train.duplicated().sum(), df_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T11:36:32.217693Z",
     "start_time": "2024-02-08T11:36:32.181425Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Собираем тестовые и тренировоные данные вместе для препроцессинга\n",
    "df = pd.concat((df_train, df_test), ignore_index=True, axis=0)\n",
    "# Удаляем Id, так как на окончательный результат он точно не влияет\n",
    "df.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          2909\n",
       "MiscFeature     2814\n",
       "Alley           2721\n",
       "Fence           2348\n",
       "MasVnrType      1766\n",
       "FireplaceQu     1420\n",
       "LotFrontage      486\n",
       "GarageFinish     159\n",
       "GarageQual       159\n",
       "GarageCond       159\n",
       "GarageYrBlt      159\n",
       "GarageType       157\n",
       "BsmtExposure      82\n",
       "BsmtCond          82\n",
       "BsmtQual          81\n",
       "BsmtFinType2      80\n",
       "BsmtFinType1      79\n",
       "MasVnrArea        23\n",
       "MSZoning           4\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "Functional         2\n",
       "Utilities          2\n",
       "GarageArea         1\n",
       "GarageCars         1\n",
       "Electrical         1\n",
       "KitchenQual        1\n",
       "TotalBsmtSF        1\n",
       "BsmtUnfSF          1\n",
       "BsmtFinSF2         1\n",
       "BsmtFinSF1         1\n",
       "Exterior2nd        1\n",
       "Exterior1st        1\n",
       "SaleType           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем список колонок с NaN объектами и их количеством\n",
    "df_nan = df.isna().sum()[df.isna().sum() > 0]\n",
    "df_nan.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Смотрим на описание данных и что пропущенные значения из себя представляют.\n",
    "> PoolQC: Pool quality \\\n",
    "       NA - No Pool\n",
    "\n",
    "> MiscFeature: Miscellaneous feature not covered in other categories \\\n",
    "       NA - None\n",
    "\n",
    "> Alley: Type of alley access to property \\\n",
    "       NA - No alley access\n",
    "\n",
    "> Fence: Fence quality \\\n",
    "       NA - No Fence\n",
    "\n",
    "> MasVnrType: Masonry veneer type \\\n",
    "       None - None\n",
    "\n",
    "> FireplaceQu: Fireplace quality \\\n",
    "       NA - No Fireplace\n",
    "\n",
    "> LotFrontage: Linear feet of street connected to property \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> GarageFinish: Interior finish of the garage \\\n",
    "       NA - No Garage\n",
    "\n",
    "> GarageQual: Garage quality \\\n",
    "       NA - No Garage\n",
    "\n",
    "> GarageCond: Garage condition \\\n",
    "       NA - No Garage\n",
    "\n",
    "> GarageYrBlt: Year garage was built\n",
    "\n",
    "> GarageType: Garage location \\\n",
    "       NA - No Garage\n",
    "\n",
    "> BsmtExposure: Refers to walkout or garden level walls \\\n",
    "       NA - No Basement\n",
    "\n",
    "> BsmtCond: Evaluates the general condition of the basement \\\n",
    "       NA - No Basement\n",
    "\n",
    "> BsmtQual: Evaluates the height of the basement \\\n",
    "       NA - No Basement\n",
    "\n",
    "> BsmtFinType2: Rating of basement finished area (if multiple types) \\\n",
    "       NA - No Basement\n",
    "\n",
    "> BsmtFinType1: Rating of basement finished area \\\n",
    "       NA - No Basement\n",
    "\n",
    "> MasVnrArea: Masonry veneer area in square feet \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> MSZoning: Identifies the general zoning classification of the sale. \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> BsmtFullBath: Basement full bathrooms \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> BsmtHalfBath: Basement half bathrooms \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "\n",
    "> Utilities: Type of utilities available \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> GarageArea: Size of garage in square feet \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> GarageCars: Size of garage in car capacity \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> Electrical: Electrical system \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> KitchenQual: Kitchen quality \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> TotalBsmtSF: Total square feet of basement area \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> Unfinished square feet of basement area \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> BsmtFinSF2: Type 2 finished square feet \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> BsmtFinSF1: Type 1 finished square feet \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> Exterior1st: Exterior covering on house \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> Exterior2nd: Exterior covering on house (if more than one material) \\\n",
    "       Нет дополнительной информации.\n",
    "\n",
    "> SaleType: Type of sale \\\n",
    "       Нет дополнительной информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобрабатываем наши данные\n",
    "preprocessor = Preprocessor()\n",
    "preprocessed_df = preprocessor.fit_transform(df, y)\n",
    "\n",
    "# Разъединяем наши данные для обучения модели и дальнейшей обработки\n",
    "preprocessed_train, preprocessed_test = preprocessed_df.iloc[:1460, :], preprocessed_df.iloc[1460:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель и сохраняем результат\n",
    "params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"random_seed\": 42,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"verbose\": 0,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "}\n",
    "\n",
    "cat_boost_rg = CatBoostRegressor(**params)\n",
    "cat_boost_rg.fit(preprocessed_train, y)\n",
    "\n",
    "predictions = np.expm1(cat_boost_rg.predict(preprocessed_test))\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "submission = pd.concat((id, predictions), axis=1)\n",
    "submission.columns = ['Id',\t'SalePrice']\n",
    "submission.to_csv(\"submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель работает,  но попытаемся улучшить метрики. Сначала посмотрим на показатели нащих метрик на текущей модели и данных\n",
    "\n",
    "# Получим данные для валидации и обучим нашу модель\n",
    "train, valid, y_train, y_valid = train_test_split(preprocessed_train, np.array(y), test_size=0.2, random_state=42)\n",
    "y_train = np.log1p(y_train)\n",
    "y_valid = np.log1p(y_valid)pre\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"random_seed\": 42,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"verbose\": 0,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"eval_metric\": \"RMSE\"\n",
    "}\n",
    "cat_boost_rg = CatBoostRegressor(**params)\n",
    "cat_boost_rg.fit(train, y_train, eval_set=(valid, y_valid));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE is 0.12719\n"
     ]
    }
   ],
   "source": [
    "best_score = cat_boost_rg.get_best_score()\n",
    "print(f\"Best RMSE is {best_score['validation']['RMSE']:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=&lt;catboost.core.CatBoostRegressor object at 0x28fe3fac0&gt;,\n",
       "    n_features_to_select=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=&lt;catboost.core.CatBoostRegressor object at 0x28fe3fac0&gt;,\n",
       "    n_features_to_select=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x28fe3fac0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x28fe3fac0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=<catboost.core.CatBoostRegressor object at 0x28fe3fac0>,\n",
       "    n_features_to_select=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Используем RFE чтобы отранжировать наши данные\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(cat_boost_rg, n_features_to_select=10)\n",
    "rfe.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value is 0.12454890344459714 with {'regressor': 'Catboost', 'learning_rate': 0.1253760286433844, 'depth': 5} parameters on 109 features\n",
      "Best value is 0.12074942277629716 with {'regressor': 'Catboost', 'learning_rate': 0.14350786359090706, 'depth': 4} parameters on 108 features\n",
      "Best value is 0.12160673777562961 with {'regressor': 'Catboost', 'learning_rate': 0.32119934962883084, 'depth': 6} parameters on 107 features\n",
      "Best value is 0.12256245670507528 with {'regressor': 'Catboost', 'learning_rate': 0.20650735822143873, 'depth': 4} parameters on 106 features\n",
      "Best value is 0.1277932413915102 with {'regressor': 'SVR', 'C': 2.0245546696661023, 'kernel': 'linear', 'gamma': 'auto'} parameters on 105 features\n",
      "Best value is 0.12076354956018413 with {'regressor': 'Catboost', 'learning_rate': 0.12687448133059653, 'depth': 6} parameters on 104 features\n",
      "Best value is 0.1217669777397567 with {'regressor': 'Catboost', 'learning_rate': 0.13478630992772858, 'depth': 4} parameters on 103 features\n",
      "Best value is 0.12228224157217338 with {'regressor': 'Catboost', 'learning_rate': 0.24961744790316348, 'depth': 3} parameters on 102 features\n",
      "Best value is 0.12133157453024676 with {'regressor': 'Catboost', 'learning_rate': 0.4254867175807764, 'depth': 5} parameters on 101 features\n",
      "Best value is 0.11997213984064896 with {'regressor': 'Catboost', 'learning_rate': 0.20737813689540302, 'depth': 3} parameters on 100 features\n",
      "Best value is 0.12106465256255435 with {'regressor': 'Catboost', 'learning_rate': 0.12319973370103972, 'depth': 5} parameters on 99 features\n",
      "Best value is 0.12059622558229599 with {'regressor': 'Catboost', 'learning_rate': 0.1326651363323055, 'depth': 5} parameters on 98 features\n",
      "Best value is 0.12025179184299269 with {'regressor': 'Catboost', 'learning_rate': 0.10969284750413213, 'depth': 5} parameters on 97 features\n",
      "Best value is 0.12208896923805146 with {'regressor': 'Catboost', 'learning_rate': 0.13529823460458293, 'depth': 5} parameters on 96 features\n",
      "Best value is 0.12310241216414029 with {'regressor': 'Catboost', 'learning_rate': 0.12902884251988705, 'depth': 6} parameters on 95 features\n",
      "Best value is 0.12233666156001062 with {'regressor': 'Catboost', 'learning_rate': 0.10008465781835413, 'depth': 4} parameters on 94 features\n",
      "Best value is 0.11797836408240701 with {'regressor': 'Catboost', 'learning_rate': 0.4308625528630038, 'depth': 4} parameters on 93 features\n",
      "Best value is 0.11915425132137056 with {'regressor': 'Catboost', 'learning_rate': 0.17088269133164824, 'depth': 4} parameters on 92 features\n",
      "Best value is 0.12190272129745316 with {'regressor': 'Catboost', 'learning_rate': 0.328488779926793, 'depth': 3} parameters on 91 features\n",
      "Best value is 0.12109941393651408 with {'regressor': 'Catboost', 'learning_rate': 0.1393502910978677, 'depth': 4} parameters on 90 features\n",
      "Best value is 0.12168750799295117 with {'regressor': 'Catboost', 'learning_rate': 0.1475571278683355, 'depth': 4} parameters on 89 features\n",
      "Best value is 0.1221863016128007 with {'regressor': 'Catboost', 'learning_rate': 0.11119019462649608, 'depth': 3} parameters on 88 features\n",
      "Best value is 0.12150026140500991 with {'regressor': 'Catboost', 'learning_rate': 0.17535855149704127, 'depth': 6} parameters on 87 features\n",
      "Best value is 0.12413107980909174 with {'regressor': 'Catboost', 'learning_rate': 0.11468282005861027, 'depth': 4} parameters on 86 features\n",
      "Best value is 0.12057371388070656 with {'regressor': 'Catboost', 'learning_rate': 0.3041723740240205, 'depth': 4} parameters on 85 features\n",
      "Best value is 0.12091690092493043 with {'regressor': 'Catboost', 'learning_rate': 0.3054255777810086, 'depth': 4} parameters on 84 features\n",
      "Best value is 0.12363325924455915 with {'regressor': 'Catboost', 'learning_rate': 0.14193266611614164, 'depth': 5} parameters on 83 features\n",
      "Best value is 0.12351279660576815 with {'regressor': 'Catboost', 'learning_rate': 0.10866754502719751, 'depth': 5} parameters on 82 features\n",
      "Best value is 0.12259304918588335 with {'regressor': 'Catboost', 'learning_rate': 0.16155538034157482, 'depth': 5} parameters on 81 features\n",
      "Best value is 0.12096853378363945 with {'regressor': 'Catboost', 'learning_rate': 0.15502789407943626, 'depth': 6} parameters on 80 features\n",
      "Best value is 0.12424372375041001 with {'regressor': 'Catboost', 'learning_rate': 0.1305071459843011, 'depth': 5} parameters on 79 features\n",
      "Best value is 0.12359778316630007 with {'regressor': 'Catboost', 'learning_rate': 0.12515702276071838, 'depth': 6} parameters on 78 features\n",
      "Best value is 0.12152916930420746 with {'regressor': 'Catboost', 'learning_rate': 0.12713400921564125, 'depth': 4} parameters on 77 features\n",
      "Best value is 0.12314041482368385 with {'regressor': 'Catboost', 'learning_rate': 0.10045955481092411, 'depth': 5} parameters on 76 features\n",
      "Best value is 0.12276373607662826 with {'regressor': 'Catboost', 'learning_rate': 0.4700151456619049, 'depth': 5} parameters on 75 features\n",
      "Best value is 0.1219447020208161 with {'regressor': 'Catboost', 'learning_rate': 0.13257986659463836, 'depth': 4} parameters on 74 features\n",
      "Best value is 0.12175950859779983 with {'regressor': 'Catboost', 'learning_rate': 0.12054143054179879, 'depth': 6} parameters on 73 features\n",
      "Best value is 0.12342155578003848 with {'regressor': 'Catboost', 'learning_rate': 0.12607552689958113, 'depth': 3} parameters on 72 features\n",
      "Best value is 0.11962971800888046 with {'regressor': 'Catboost', 'learning_rate': 0.3847237648922792, 'depth': 4} parameters on 71 features\n",
      "Best value is 0.12300728825179327 with {'regressor': 'Catboost', 'learning_rate': 0.2065035335399979, 'depth': 5} parameters on 70 features\n",
      "Best value is 0.11958367128310472 with {'regressor': 'Catboost', 'learning_rate': 0.1570732355951173, 'depth': 4} parameters on 69 features\n",
      "Best value is 0.12421383568204941 with {'regressor': 'Catboost', 'learning_rate': 0.13835011888763635, 'depth': 5} parameters on 68 features\n",
      "Best value is 0.12216264091309263 with {'regressor': 'Catboost', 'learning_rate': 0.12413126567002156, 'depth': 4} parameters on 67 features\n",
      "Best value is 0.12128393716922399 with {'regressor': 'Catboost', 'learning_rate': 0.2378769627369856, 'depth': 4} parameters on 66 features\n",
      "Best value is 0.12297108349870767 with {'regressor': 'Catboost', 'learning_rate': 0.10066344024137093, 'depth': 6} parameters on 65 features\n",
      "Best value is 0.1226224519667204 with {'regressor': 'Catboost', 'learning_rate': 0.1376706285859702, 'depth': 5} parameters on 64 features\n",
      "Best value is 0.1209637192018927 with {'regressor': 'Catboost', 'learning_rate': 0.28592123981235473, 'depth': 3} parameters on 63 features\n",
      "Best value is 0.12130231864408142 with {'regressor': 'Catboost', 'learning_rate': 0.10725741280212142, 'depth': 3} parameters on 62 features\n",
      "Best value is 0.12253283880575287 with {'regressor': 'Catboost', 'learning_rate': 0.13682231831608294, 'depth': 4} parameters on 61 features\n",
      "Best value is 0.12423773784372688 with {'regressor': 'Catboost', 'learning_rate': 0.2699966373112148, 'depth': 5} parameters on 60 features\n",
      "Best value is 0.12213967494745458 with {'regressor': 'Catboost', 'learning_rate': 0.3272048764723911, 'depth': 4} parameters on 59 features\n",
      "Best value is 0.12168628707849294 with {'regressor': 'Catboost', 'learning_rate': 0.12129894101172341, 'depth': 3} parameters on 58 features\n",
      "Best value is 0.12128788262290273 with {'regressor': 'Catboost', 'learning_rate': 0.3378777324859804, 'depth': 4} parameters on 57 features\n",
      "Best value is 0.11803698898804404 with {'regressor': 'Catboost', 'learning_rate': 0.23791988864426977, 'depth': 3} parameters on 56 features\n",
      "Best value is 0.122929582957961 with {'regressor': 'Catboost', 'learning_rate': 0.10925508801893283, 'depth': 4} parameters on 55 features\n",
      "Best value is 0.12253321690538481 with {'regressor': 'Catboost', 'learning_rate': 0.19480822795158292, 'depth': 6} parameters on 54 features\n",
      "Best value is 0.1230328417441504 with {'regressor': 'Catboost', 'learning_rate': 0.16919777065438815, 'depth': 4} parameters on 53 features\n",
      "Best value is 0.12386863336811534 with {'regressor': 'Catboost', 'learning_rate': 0.10040664159184468, 'depth': 4} parameters on 52 features\n",
      "Best value is 0.1235174459094106 with {'regressor': 'Catboost', 'learning_rate': 0.4813469028546995, 'depth': 3} parameters on 51 features\n",
      "Best value is 0.12670261799206903 with {'regressor': 'Catboost', 'learning_rate': 0.1385013737541972, 'depth': 6} parameters on 50 features\n",
      "Best value is 0.12212563649420378 with {'regressor': 'Catboost', 'learning_rate': 0.2029106492307544, 'depth': 5} parameters on 49 features\n",
      "Best value is 0.12931277897189677 with {'regressor': 'Catboost', 'learning_rate': 0.12148496009427981, 'depth': 7} parameters on 48 features\n",
      "Best value is 0.1250189590586926 with {'regressor': 'Catboost', 'learning_rate': 0.11556877156737441, 'depth': 4} parameters on 47 features\n",
      "Best value is 0.12804967098269762 with {'regressor': 'Catboost', 'learning_rate': 0.11909837929051041, 'depth': 4} parameters on 46 features\n",
      "Best value is 0.1275673252747175 with {'regressor': 'Catboost', 'learning_rate': 0.10670408786816579, 'depth': 6} parameters on 45 features\n",
      "Best value is 0.1275577204749568 with {'regressor': 'Catboost', 'learning_rate': 0.2213952784844528, 'depth': 5} parameters on 44 features\n",
      "Best value is 0.1284092794059662 with {'regressor': 'Catboost', 'learning_rate': 0.10007659420515565, 'depth': 6} parameters on 43 features\n",
      "Best value is 0.12690985445243427 with {'regressor': 'Catboost', 'learning_rate': 0.1413720832812014, 'depth': 5} parameters on 42 features\n",
      "Best value is 0.12856153823167502 with {'regressor': 'Catboost', 'learning_rate': 0.2589683638642447, 'depth': 4} parameters on 41 features\n",
      "Best value is 0.12600370983920897 with {'regressor': 'Catboost', 'learning_rate': 0.2678196673916628, 'depth': 5} parameters on 40 features\n",
      "Best value is 0.1255569765873888 with {'regressor': 'Catboost', 'learning_rate': 0.32346835541804786, 'depth': 4} parameters on 39 features\n",
      "Best value is 0.12785791556007933 with {'regressor': 'Catboost', 'learning_rate': 0.25542183991689194, 'depth': 4} parameters on 38 features\n",
      "Best value is 0.1280743406589804 with {'regressor': 'Catboost', 'learning_rate': 0.12544417909746036, 'depth': 5} parameters on 37 features\n",
      "Best value is 0.12739668587570446 with {'regressor': 'Catboost', 'learning_rate': 0.34766539661569695, 'depth': 3} parameters on 36 features\n",
      "Best value is 0.1290053475246992 with {'regressor': 'Catboost', 'learning_rate': 0.13612032110900013, 'depth': 6} parameters on 35 features\n",
      "Best value is 0.12960708586616693 with {'regressor': 'Catboost', 'learning_rate': 0.22512190840617427, 'depth': 4} parameters on 34 features\n",
      "Best value is 0.12709669438998483 with {'regressor': 'Catboost', 'learning_rate': 0.23783010953848724, 'depth': 4} parameters on 33 features\n",
      "Best value is 0.12926788763467562 with {'regressor': 'Catboost', 'learning_rate': 0.293284101164925, 'depth': 4} parameters on 32 features\n",
      "Best value is 0.12734476465357566 with {'regressor': 'Catboost', 'learning_rate': 0.17994660148804437, 'depth': 6} parameters on 31 features\n",
      "Best value is 0.1281144237057958 with {'regressor': 'Catboost', 'learning_rate': 0.22247016795546604, 'depth': 6} parameters on 30 features\n",
      "Best value is 0.12957757234310466 with {'regressor': 'Catboost', 'learning_rate': 0.11415911467888787, 'depth': 4} parameters on 29 features\n",
      "Best value is 0.12945482394213662 with {'regressor': 'Catboost', 'learning_rate': 0.1262562187511569, 'depth': 5} parameters on 28 features\n",
      "Best value is 0.1286864237537156 with {'regressor': 'Catboost', 'learning_rate': 0.11003928574067619, 'depth': 4} parameters on 27 features\n",
      "Best value is 0.1305178525249858 with {'regressor': 'Catboost', 'learning_rate': 0.15107164509787444, 'depth': 3} parameters on 26 features\n",
      "Best value is 0.13020818667377906 with {'regressor': 'Catboost', 'learning_rate': 0.2442086792962096, 'depth': 4} parameters on 25 features\n",
      "Best value is 0.12620505381188632 with {'regressor': 'Catboost', 'learning_rate': 0.4131881008721741, 'depth': 6} parameters on 24 features\n",
      "Best value is 0.1270558340544481 with {'regressor': 'Catboost', 'learning_rate': 0.3021397526057611, 'depth': 5} parameters on 23 features\n",
      "Best value is 0.1276617384583348 with {'regressor': 'Catboost', 'learning_rate': 0.1263921850332806, 'depth': 5} parameters on 22 features\n",
      "Best value is 0.12917628784406235 with {'regressor': 'SVR', 'C': 9.993690848583494, 'kernel': 'rbf', 'gamma': 'auto'} parameters on 21 features\n",
      "Best value is 0.12852581999825205 with {'regressor': 'Catboost', 'learning_rate': 0.19878133198351405, 'depth': 3} parameters on 20 features\n",
      "Best value is 0.12902603910173924 with {'regressor': 'Catboost', 'learning_rate': 0.1460593355598297, 'depth': 3} parameters on 19 features\n",
      "Best value is 0.133108956148559 with {'regressor': 'SVR', 'C': 9.149056005736979, 'kernel': 'rbf', 'gamma': 'auto'} parameters on 18 features\n",
      "Best value is 0.13035098019693186 with {'regressor': 'Catboost', 'learning_rate': 0.1322344123299354, 'depth': 3} parameters on 17 features\n",
      "Best value is 0.13080339161479346 with {'regressor': 'Catboost', 'learning_rate': 0.11798402313978498, 'depth': 7} parameters on 16 features\n",
      "Best value is 0.12879826054746057 with {'regressor': 'Catboost', 'learning_rate': 0.14328675424952508, 'depth': 5} parameters on 15 features\n",
      "Best value is 0.1298794866871731 with {'regressor': 'SVR', 'C': 1.9021920049200411, 'kernel': 'rbf', 'gamma': 'scale'} parameters on 14 features\n",
      "Best value is 0.12663877247039226 with {'regressor': 'Catboost', 'learning_rate': 0.3295123708064702, 'depth': 5} parameters on 13 features\n",
      "Best value is 0.12753799225491905 with {'regressor': 'Catboost', 'learning_rate': 0.18403603585214556, 'depth': 4} parameters on 12 features\n",
      "Best value is 0.1331599755389568 with {'regressor': 'Catboost', 'learning_rate': 0.33990885997325243, 'depth': 7} parameters on 11 features\n",
      "Best value is 0.13713036241748947 with {'regressor': 'Catboost', 'learning_rate': 0.17261999981090337, 'depth': 4} parameters on 10 features\n",
      "Best value is 0.14640936661499337 with {'regressor': 'SVR', 'C': 4.435160524150603, 'kernel': 'rbf', 'gamma': 'scale'} parameters on 9 features\n",
      "Best value is 0.14769047992541676 with {'regressor': 'Catboost', 'learning_rate': 0.25608016607690276, 'depth': 3} parameters on 8 features\n",
      "Best value is 0.1627882781602127 with {'regressor': 'Catboost', 'learning_rate': 0.11957518384664809, 'depth': 6} parameters on 7 features\n",
      "Best value is 0.16466494988498503 with {'regressor': 'Catboost', 'learning_rate': 0.16105263427339464, 'depth': 4} parameters on 6 features\n",
      "Best value is 0.18797582631971513 with {'regressor': 'Catboost', 'learning_rate': 0.1339449909237668, 'depth': 6} parameters on 5 features\n",
      "Best value is 0.19618405075700007 with {'regressor': 'Catboost', 'learning_rate': 0.2651181718899881, 'depth': 7} parameters on 4 features\n",
      "Best value is 0.21105689461039132 with {'regressor': 'Catboost', 'learning_rate': 0.48015081905396495, 'depth': 3} parameters on 3 features\n",
      "Best value is 0.2294272957046981 with {'regressor': 'Catboost', 'learning_rate': 0.45480279475645996, 'depth': 4} parameters on 2 features\n",
      "Best value is 0.3078907340724363 with {'regressor': 'Catboost', 'learning_rate': 0.44430186220824663, 'depth': 7} parameters on 1 features\n"
     ]
    }
   ],
   "source": [
    "# Используем optuna для настройки оптимальных параметров\n",
    "\n",
    "best_params = []\n",
    "best_values = []\n",
    "for i in range(len(ranking)):\n",
    "    train, valid, y_train, y_valid = train_test_split(preprocessed_train1, np.array(y), test_size=0.2, random_state=42)\n",
    "    y_train = np.log1p(y_train)\n",
    "    y_valid = np.log1p(y_valid)\n",
    "    \n",
    "    def objective(trial):\n",
    "        regressors = [\"RandomForest\", \"Catboost\", \"LinearRegression\", \"SVR\", \"KNN\", \"XGBoost\", \"lgb\"] \n",
    "    \n",
    "        regressor_name = trial.suggest_categorical(\"regressor\", regressors)\n",
    "        \n",
    "        if regressor_name == \"RandomForest\":\n",
    "            model_params = {\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "                    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "                    \"max_features\": trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "                    \"random_state\": 42,\n",
    "                    \"n_jobs\": -1\n",
    "                }\n",
    "    \n",
    "            model = RandomForestRegressor(**model_params)\n",
    "            model.fit(train, y_train)\n",
    "            y_pred = model.predict(valid)\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    \n",
    "            \n",
    "        elif regressor_name == \"LinearRegression\":\n",
    "            model_params = {\n",
    "                    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "                }\n",
    "    \n",
    "            model = LinearRegression(**model_params)\n",
    "            model.fit(train, y_train)\n",
    "            y_pred = model.predict(valid)\n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "    \n",
    "     \n",
    "        elif regressor_name == \"Catboost\":\n",
    "            model_params = {\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.1, 0.5),\n",
    "                    \"depth\": trial.suggest_int(\"depth\", 3, 7),\n",
    "                    \"random_seed\": 42,\n",
    "                    \"loss_function\": \"RMSE\",\n",
    "                    \"verbose\": 0,\n",
    "                    \"early_stopping_rounds\": 5,\n",
    "                    \"eval_metric\": \"RMSE\",\n",
    "                    \"iterations\":300\n",
    "                }\n",
    "            model = CatBoostRegressor(**model_params)\n",
    "            model.fit(\n",
    "                train,\n",
    "                y_train,\n",
    "                eval_set=(valid, y_valid)\n",
    "                )\n",
    "            \n",
    "            rmse = model.best_score_[\"validation\"][\"RMSE\"]\n",
    "        elif regressor_name == \"SVR\":\n",
    "        \n",
    "            model_params = {\n",
    "                'C': trial.suggest_float('C', 0.1, 10, log=True),\n",
    "                'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', ]), #'sigmoid'\n",
    "                'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "            }\n",
    "            \n",
    "            model = SVR(**model_params)\n",
    "            model.fit(train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(valid)\n",
    "            \n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "        elif regressor_name == \"KNN\":\n",
    "        \n",
    "            model_params = {\n",
    "                'n_neighbors': trial.suggest_int('n_neighbors', 1, 20),\n",
    "                'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            }\n",
    "            \n",
    "            model = KNeighborsRegressor(**model_params)\n",
    "            model.fit(train, y_train)\n",
    "            \n",
    "            y_pred = model.predict(valid)\n",
    "            \n",
    "            rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "        elif regressor_name == \"XGBoost\":\n",
    "        \n",
    "            model_params = {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.5),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'random_state': 42,\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'rmse',\n",
    "            }\n",
    "            dtrain = xgb.DMatrix(train, label=y_train)\n",
    "            dvalid = xgb.DMatrix(valid, label=y_valid)\n",
    "            \n",
    "            model = xgb.train(model_params, dtrain, evals=[(dvalid, 'validation')], early_stopping_rounds=5, verbose_eval=False)\n",
    "            \n",
    "            rmse = model.best_score\n",
    "\n",
    "        elif regressor_name == \"lgb\":\n",
    "        \n",
    "            model_params = {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.5),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "                'random_state': 42,\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                \"verbose\" : -1\n",
    "            }\n",
    "\n",
    "            train_data = lgb.Dataset(train, label=y_train)\n",
    "            valid_data = lgb.Dataset(valid, label=y_valid, reference=train_data)\n",
    "            \n",
    "            model = lgb.train(model_params, train_data,valid_sets=[valid_data], num_boost_round=50)\n",
    "            \n",
    "            rmse = model.best_score[\"valid_0\"][\"rmse\"]\n",
    "    \n",
    "        \n",
    "        return rmse\n",
    "\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    study.optimize(objective, n_trials=700)\n",
    "    \n",
    "    best_param = study.best_params\n",
    "    best_value = study.best_value\n",
    "    best_params.append(study.best_params)\n",
    "    best_values.append(study.best_value)\n",
    "    \n",
    "    print(f\"Best value is {best_value} with {best_param} parameters on {len(ranking)} features\")\n",
    "    preprocessed_train1 = preprocessed_train1.drop(preprocessed_train1.columns[np.argmax(ranking)], axis=1)\n",
    "    ranking = np.delete(ranking, np.argmax(ranking))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor': 'Catboost', 'learning_rate': 0.4308625528630038, 'depth': 4}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Смотрим самый лучшие параметеры\n",
    "np.array(best_values)\n",
    "best_param = best_params[np.argmin(best_values)]\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 93)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Уменьшаем нашу выборку до полученного значения фичей\n",
    "for i in range(len(ranking) - 93):\n",
    "    preprocessed_train = preprocessed_train.drop(preprocessed_train.columns[np.argmax(ranking)], axis=1)\n",
    "    ranking = np.delete(ranking, np.argmax(ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE is 0.11798\n"
     ]
    }
   ],
   "source": [
    "# Обучаем нашу модель на полученных данных\n",
    "train, valid, y_train, y_valid = train_test_split(preprocessed_train, np.array(y), test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.log1p(y_train)\n",
    "y_valid = np.log1p(y_valid)\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": 0.4308625528630038,\n",
    "    \"depth\": 4,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    \"random_seed\": 42,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"verbose\": 0,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"eval_metric\": \"RMSE\"\n",
    "}\n",
    "\n",
    "cat_boost_rg = CatBoostRegressor(**params)\n",
    "cat_boost_rg.fit(train, y_train, eval_set=(valid, y_valid))\n",
    "best_rmse = cat_boost_rg.get_best_score()['validation']['RMSE']\n",
    "print(f\"Best RMSE is {best_rmse:.5f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем полученный результат и полученную модель\n",
    "predictions = np.expm1(cat_boost_rg.predict(preprocessed_test))\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "submission = pd.concat((id, predictions), axis=1)\n",
    "submission.columns = ['Id',\t'SalePrice']\n",
    "submission.to_csv(\"submission1.csv\", index=False)\n",
    "\n",
    "model = cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
